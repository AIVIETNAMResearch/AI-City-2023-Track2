{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/AIC23_Track2_NL_Retrieval/data/test-tracks.json\") as f:\n",
    "    test_tracks = json.load(f)\n",
    "\n",
    "with open(\"../data/AIC23_Track2_NL_Retrieval/data/test-queries.json\") as f:\n",
    "    test_queries = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nl': ['A white sedan turns right at an intersection following another red sedan.',\n",
       "  'A white sedan turns right.',\n",
       "  'A white sedan turns right after another car.'],\n",
       " 'nl_other_views': ['A gray sedan crosses the intersection keeping straight.',\n",
       "  'A gray sedan keeps straight.',\n",
       "  'A gray sedan going straight down the street.',\n",
       "  'A gray sedan keeping straight on the right side of the street.',\n",
       "  'A silver sedan.',\n",
       "  'A silver sedan runs down the street.']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_queries[\"8d356ab3-2427-488c-8f55-c1aa27bb6c7f\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'4cf64bda-3fb7-4d74-b28f-ce4d7e20865b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1248644/2914689069.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_tracks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"4cf64bda-3fb7-4d74-b28f-ce4d7e20865b\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '4cf64bda-3fb7-4d74-b28f-ce4d7e20865b'"
     ]
    }
   ],
   "source": [
    "track = test_tracks[\"4cf64bda-3fb7-4d74-b28f-ce4d7e20865b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'straight', 2: 'stop', 3: 'left', 4: 'right'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    1: 'straight',\n",
    "    2: 'stop',\n",
    "    3: 'left',\n",
    "    4: 'right'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (108610378.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_878217/108610378.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    with open(\"post_process/target_test_direction_predict_one_hot_refinement.json\") as f;\u001b[0m\n\u001b[0m                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "f, axarr = plt.subplots(2,2)\n",
    "axarr = axarr.flatten()\n",
    "\n",
    "\n",
    "\n",
    "data_path = \"../data/AIC23_Track2_NL_Retrieval/data/\"\n",
    "for frame, ax in zip(track['frames'][:4], axarr):\n",
    "    image = Image.open(os.path.join(data_path, frame[2:]))\n",
    "    ax.imshow(image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Pseudo Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [00:00<00:00, 459.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "clip_feats_mat = torch.load(\"../data/AIC23_Track2_NL_Retrieval/data/clip_feats_mat.pth\").detach().cpu().numpy().T\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open(\"../post_process/target_test_direction_predict_one_hot_refinement.json\") as f:\n",
    "    test_direction = json.load(f)\n",
    "\n",
    "loc_dict = {'c005': 1, 'c014': 0, 'c029': 0, 'c003': 1, 'c017': 0, 'c035': 0, 'c013': 0, 'c027': 0, 'c038': 0,\n",
    "                    'c016': 0, 'c002': 1, 'c021': 0, 'c019': 0, 'c030': 0, 'c020': 0, 'c026': 0, 'c010': 0, 'c004': 1,\n",
    "                    'c033': 0, 'c012': 1, 'c001': 1, 'c034': 0, 'c022': 0, 'c036': 0, 'c040': 1, 'c025': 0, 'c032': 0,\n",
    "                    'c037': 1}\n",
    "\n",
    "for idx, (key, val) in enumerate(tqdm(test_tracks.items())):\n",
    "    text_id = np.argmax(clip_feats_mat[idx])\n",
    "    text = test_queries[list(test_queries.keys())[text_id]]['nl'][0]\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        name_object = chunk.text\n",
    "        break\n",
    "    \n",
    "    test_tracks[key]['nl'] = []\n",
    "\n",
    "    for i in range(3):\n",
    "        new_text = f\"A {name_object.lower()}\"\n",
    "\n",
    "        direction_pred = test_direction[key]\n",
    "        if direction_pred[0] == 1:\n",
    "            straight_opts = [\"drives forward\", \"moving straight\", \"drives straight\", \"drive downs\", \"run downs\"]\n",
    "            straight_text = straight_opts[np.random.randint(0, len(straight_opts))]\n",
    "            new_text += f\" {straight_text}\"\n",
    "        elif direction_pred[1] == 1:\n",
    "            stop_opts = [\"park\", \"stops\", \"is stopping\"]\n",
    "            stop_text = stop_opts[np.random.randint(0, len(stop_opts))]\n",
    "            new_text += f\" {stop_text}\"\n",
    "\n",
    "        elif direction_pred[2] == 1:\n",
    "            left_opts = [\"moves left\", \"turns left\", \"keeps left\"]\n",
    "            left_text = left_opts[np.random.randint(0, len(left_opts))]\n",
    "\n",
    "            new_text += f\" {left_text}\"\n",
    "        elif direction_pred[3] == 1:\n",
    "            right_opts = [\"moves right\", \"turns right\", \"keeps right\"]\n",
    "            right_text = right_opts[np.random.randint(0, len(right_opts))]\n",
    "\n",
    "            new_text += f\" {right_text}\"\n",
    "\n",
    "        cam_id = val['frames'][0].split(\"/\")[3]\n",
    "        if loc_dict[cam_id] == 1:\n",
    "            new_text += \" at an intersection.\"\n",
    "        else:\n",
    "            new_text += \".\"\n",
    "    \n",
    "        test_tracks[key]['nl'].append(new_text)\n",
    "        \n",
    "    test_tracks[key]['nl_other_views'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tracks['18e09c74-6a9e-4432-9a2a-b28c85a34285']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pseudo_label files:\n",
    "with open(\"../data/AIC23_Track2_NL_Retrieval/data/pseudo_test_tracks.json\", 'w') as f:\n",
    "    json.dump(test_tracks, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-splitter in /home/aivn2023/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages (1.4)\n",
      "Requirement already satisfied: SentencePiece in /home/aivn2023/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages (0.1.97)\n",
      "Requirement already satisfied: regex>=2017.12.12 in /home/aivn2023/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages (from sentence-splitter) (2022.10.31)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: regex in /home/aivn2023/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages (from sacremoses) (2022.10.31)\n",
      "Requirement already satisfied: six in /home/aivn2023/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages (from sacremoses) (1.16.0)\n",
      "Requirement already satisfied: click in /home/aivn2023/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages (from sacremoses) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/aivn2023/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages (from sacremoses) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /home/aivn2023/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages (from sacremoses) (4.64.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=b09fff0419397f36b67490e6fe7e8317cdf0af4e1daa8e209949461e03209dbf\n",
      "  Stored in directory: /home/aivn2023/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses\n",
      "Successfully installed sacremoses-0.0.53\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-splitter SentencePiece\n",
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aivn2023/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "\n",
    "model_name = \"tuner007/pegasus_paraphrase\"\n",
    "torch_device = \"cpu\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_aug(\n",
    "    input_text, num_return_sequences=1, num_beams=1, max_length=100, temperature=0\n",
    "):\n",
    "    batch = tokenizer(\n",
    "        [input_text],\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(torch_device)\n",
    "    translated = model.generate(\n",
    "        **batch,\n",
    "        max_length=max_length,\n",
    "        num_beams=num_beams,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os \n",
    "import sys\n",
    "import uuid\n",
    "import cv2\n",
    "os.chdir(os.path.dirname('/media/aivn2023/86c50d28-d521-419b-a569-3aab9993961f/media/ai2023/HungAn/Track2-Vehicle-Retrieval/Track2-Vehicle_Retrieval/configs'))\n",
    "\n",
    "\n",
    "with open(\"data/AIC23_Track2_NL_Retrieval/data/test-tracks.json\") as f:\n",
    "    test_tracks = json.load(f)\n",
    "\n",
    "with open(\"data/AIC23_Track2_NL_Retrieval/data/test-queries.json\") as f:\n",
    "    test_queries = json.load(f)\n",
    "\n",
    "with open('submissions/submit_10_45ath.json') as f:\n",
    "    test_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from preprocessing.transforms import build_transforms, build_vanilla_transforms, build_motion_transform, BackTranslateAug\n",
    "# trans_aug = BackTranslateAug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "['A blue pickup truck keeps straight at an intersection.', 'A blue pickup drives through the intersection.', 'A blue Pickup Truck running down the street.']\n",
      "[['A blue pickup truck is driving.'], ['A blue pickup is driving.'], ['A blue pickup truck is outside.']]\n",
      "----------------------------------------\n",
      "['A large dark gray pickup crosses an intersection.', 'A pickup leads others.', 'A grey pickup truck runs down the road alongside a truck.']\n",
      "[['A pickup crosses an intersection.'], ['A pickup is driving.'], ['A grey pickup truck is driving down the road.']]\n",
      "----------------------------------------\n",
      "['A blue sedan drives through an intersection.', 'A blue sedan moves straight passing cargo truck on the intersection.', 'A blue sedan runs through an intersection.']\n",
      "[['A blue sedan is driving.'], ['A blue sedan is passing a cargo truck.'], ['A blue sedan is driving.']]\n",
      "----------------------------------------\n",
      "['A big green cargo truck drives down an intersection with many smaller cars running in different directions.', 'The large green flatbed 18 wheeler is going straight.', 'A green semi-truck drives through an intersection.']\n",
      "[['A big green cargo truck drives down an intersection with many smaller cars running in different directions.'], ['The green flatbed is moving.'], ['A semi-truck drives through an intersection']]\n",
      "----------------------------------------\n",
      "['A red sedan switches lane to left and passes a cargo truck.', 'A red sedan keeps straight through an intersection.', 'A dark-red car is going straight.']\n",
      "[['A red sedan lane is switched to the left.'], ['A red car drives through an intersection.'], ['A car is moving.']]\n",
      "----------------------------------------\n",
      "['A gray SUV goes straight in the road.', 'A silver car waits at the intersection.', 'Silver van going trough intersection.']\n",
      "[['A gray SUV is driving.'], ['A car is at an intersection.'], ['A van is going through an intersection.']]\n",
      "----------------------------------------\n",
      "['A black SUV going straight down the street passing an intersection.', 'A wagon stops at the traffic light and then goes across the intersection.', 'A large SUV drives straight through the intersection in the left lane.']\n",
      "[['A black SUV is going down the street.'], ['A wagon stops at the traffic light.'], ['A large SUV drives through the intersection.']]\n",
      "----------------------------------------\n",
      "['A black jeep turns right while other vehicles continue to move straight.', 'A black SUV turns right.', 'A black SUV is turning right.']\n",
      "[['A black jeep is turning right while other vehicles are moving straight.'], ['A black SUV is turning.'], ['A black SUV is turning.']]\n",
      "----------------------------------------\n",
      "['A silver sedan keeps straight and overtakes a giant cargo truck.', 'A white Sedan going straight down the street passing an intersection.', 'A silver sedan drives through an intersection.']\n",
      "[['A silver sedan overtakes a giant cargo truck.'], ['A white car is going down the street.'], ['A car drives through an intersection.']]\n",
      "----------------------------------------\n",
      "['White pick up truck follow the car and stops at the intersection before proceeding.', 'White Pickup truck going straight.', 'A white pickup going straight at the intersection.']\n",
      "[['A white pick up truck stops at the intersection after following a car.'], ['The white pickup truck is going straight.'], ['A white pickup is going straight.']]\n",
      "----------------------------------------\n",
      "['A white pickup truck goes straight and passes through an intersection.', 'A white pick up truck moving straight.', 'A white truck drives straight through the intersection in the left lane.']\n",
      "[['A white pickup truck is going through an intersection.'], ['A white pick up truck is moving.'], ['A white truck drives through the intersection.']]\n",
      "----------------------------------------\n",
      "['A blue wagon going straight down the street passing an intersection.', 'A gray SUV runs down the street.', 'A gray SUV drives across an intersection.']\n",
      "[['A blue wagon is going down the street.'], ['A gray SUV is outside.'], ['A gray SUV is driving.']]\n",
      "----------------------------------------\n",
      "['A blue sedan crosses a large intersection.', 'A blue sedan goes straight down the street.', 'Blue sedan going straight through the intersection.']\n",
      "[['A blue sedan crosses a street.'], ['A blue sedan is going down the street.'], ['A blue sedan is going through an intersection.']]\n",
      "----------------------------------------\n",
      "['A red pickup goes straight at the intersection.', 'A red pickup runs at the intersection.', 'A pickup truck goes straight.']\n",
      "[['A pickup goes straight.'], ['A pickup runs through a street.'], ['A pickup truck is moving.']]\n",
      "----------------------------------------\n",
      "['A gray car drives through an intersection.', 'A white sedan runs down the street.', 'A silver coupe drives straight through an intersection in the right lane.']\n",
      "[['A car drives through an intersection'], ['A car runs down the street.'], ['A car drives through an intersection.']]\n",
      "----------------------------------------\n",
      "['A black sedan runs down the street.', 'A blue sedan is driving forward.', 'A blue sedan going straight at the intersection.']\n",
      "[['A black car is on the street.'], ['A blue car is moving.'], ['A blue sedan is going straight.']]\n",
      "----------------------------------------\n",
      "['A gray MPV runs down the street.', 'A silver van is crossing an intersection.', 'A silver wagon keeps straight.']\n",
      "[['A gray car is running down the street.'], ['A van is crossing a street.'], ['A wagon is straight.']]\n",
      "----------------------------------------\n",
      "['A gray sedan drives through a green traffic light followed by a silver van.', 'A gray Sedan running straight.', 'A grey sedan is driving straight thru an intersection.']\n",
      "[['A gray sedan drives through a green traffic light followed by a silver van.'], ['A gray car is running.'], ['A grey sedan is driving.']]\n",
      "----------------------------------------\n",
      "['Tan pickup truck travels through the intersection.', 'A brown pickup truck runs through the intersection.', 'A brown pickup truck is crossing straight through an intersection at the highway.']\n",
      "[['A pickup truck is driving through an intersection.'], ['A brown pickup truck is driving.'], ['A brown pickup truck is crossing the highway.']]\n",
      "----------------------------------------\n",
      "['A silver wagon is driving straight.', 'Grey minivan in high speed keeping straight on a low traffic street.', 'A silver van runs across an intersection behind a gray vehicle.']\n",
      "[['A wagon is driving.'], ['A minivan is in high speed and is on a street.'], ['A van runs across the intersection.']]\n",
      "----------------------------------------\n",
      "['A dark truck drives straight through the intersection.', 'A black pickup truck keeping straight on the street.', 'A blue pick up truck running down straight on a freeway.']\n",
      "[['A truck drives through the intersection.'], ['A black pickup truck is driving.'], ['A blue pick up truck is on the freeway.']]\n",
      "----------------------------------------\n",
      "['A blue SUV runs down the highway.', 'A blue SUV continues driving straight.', 'A blue SUV runs down the road behind a black SUV.']\n",
      "[['A blue SUV is outside.'], ['A blue SUV is driving.'], ['A blue SUV is running down the road.']]\n",
      "----------------------------------------\n",
      "['A white sedan turns right at an intersection.', 'An off-white sedan turns right at an intersection.', 'A light sedan turns right at the intersection.']\n",
      "[['A white sedan is turning.'], ['An off-white car turns right.'], ['A light sedan is turning.']]\n",
      "----------------------------------------\n",
      "['A white SUV goes straight down the street.', 'A white SUV going straight across an intersection at a medium rate of speed.', 'A white SUV go straight at the street.']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1295787/444999990.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtexts_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparaphrase_aug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1295787/444999990.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtexts_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparaphrase_aug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1295787/3333154226.py\u001b[0m in \u001b[0;36mparaphrase_aug\u001b[0;34m(input_text, num_return_sequences, num_beams, max_length, temperature)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     ).to(torch_device)\n\u001b[0;32m---> 11\u001b[0;31m     translated = model.generate(\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m             \u001b[0;31m# 10. run greedy search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             return self.greedy_search(\n\u001b[0m\u001b[1;32m   1491\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2233\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2234\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 )\n\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1402\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1090\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1093\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;31m# reuse k, v, self_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1121_env/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pseudo_labels = {}\n",
    "\n",
    "for i, (key, val) in enumerate(test_results.items()):\n",
    "    print(40*\"-\")\n",
    "    query = test_queries[key]\n",
    "    nls = query['nl']\n",
    "    print(nls)\n",
    "    texts_aug = [paraphrase_aug(nl) for nl in nls]\n",
    "    print(texts_aug)\n",
    "    \n",
    "    # for i in range(3):\n",
    "    #     track_id = val[i]\n",
    "    #     track = test_tracks[track_id]\n",
    "    #     id = uuid.uuid1().__str__()\n",
    "\n",
    "    #     pseudo_labels[id] = {\n",
    "    #         'frames': track['frames'],\n",
    "    #         'boxes': track['boxes'],\n",
    "    #         'nl': query['nl'],\n",
    "    #         'nl_other_views': query['nl_other_views']\n",
    "    #     }\n",
    "    #     print(track_id)\n",
    "    #     motion_line_path = f\"../data/AIC23_Track2_NL_Retrieval/data/motion_map/{track_id}.jpg\"\n",
    "    #     save_motion_path = f\"../data/AIC23_Track2_NL_Retrieval/data/motion_map/{id}.jpg\"\n",
    "    #     motion_img = cv2.imread(motion_line_path)\n",
    "    #     cv2.imwrite(save_motion_path, motion_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/AIC23_Track2_NL_Retrieval/data/train-tracks.json\") as f:\n",
    "    train_tracks = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in train_tracks.items():\n",
    "    pseudo_labels[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2707"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pseudo_labels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pseudo_label files:\n",
    "with open(\"../data/AIC23_Track2_NL_Retrieval/data/pseudo_test_tracks.json\", 'w') as f:\n",
    "    json.dump(pseudo_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1121_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8569045e15b11543999fc62c48593176458b9767f19dc62a9c1d5aa1e4e3600f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
