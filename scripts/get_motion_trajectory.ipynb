{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 17:37:30.357828: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-23 17:37:36.224328: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-23 17:37:46.220963: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dat09/venv3.7/lib/python3.7/site-packages/cv2/../../lib64:/home/dat09/TensorRT-8.5.2.2/lib:/usr/local/cuda/lib64:/usr/local/cuda-11.6/lib64:\n",
      "2023-03-23 17:37:46.221191: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dat09/venv3.7/lib/python3.7/site-packages/cv2/../../lib64:/home/dat09/TensorRT-8.5.2.2/lib:/usr/local/cuda/lib64:/usr/local/cuda-11.6/lib64:\n",
      "2023-03-23 17:37:46.221203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-23 17:38:00.991471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-23 17:38:01.034272: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-23 17:38:01.034377: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path as osp\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import glob\n",
    "import argparse\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/AIC23_Track2_NL_Retrieval/data/test-tracks.json\") as f:\n",
    "    tracks_test = json.load(f)\n",
    "with open(\"../data/AIC23_Track2_NL_Retrieval/data/train-tracks.json\") as f:\n",
    "    tracks_train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [\n",
    "    [{\"POS\": \"VERB\", \"op\": \"+\"}, {\"LOWER\": \"straight\"}],\n",
    "    [{\"POS\": \"VERB\", \"op\": \"+\"}, {\"LOWER\": \"left\"}],\n",
    "    [{\"POS\": \"VERB\", \"op\": \"+\"}, {\"LOWER\": \"right\"}],\n",
    "    [{\"POS\": \"VERB\", \"op\": \"+\"}, {\"LOWER\": \"ahead\"}],\n",
    "    [{\"LOWER\": \"stop\"}],\n",
    "    [{\"LOWER\": \"stops\"}],   \n",
    "          ]\n",
    "matcher.add(\"motion-chunks\", pattern)\n",
    "def get_motion(text):\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    output = None\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        output = span.text\n",
    "        break\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_heatmap_dir = osp.join(\"../data/AIC23_Track2_NL_Retrieval/data\", \"data/motion_line\")\n",
    "os.makedirs(save_heatmap_dir, exist_ok=True)\n",
    "\n",
    "def get_motion_line(data_dir, uuid, boxes_list):\n",
    "    path = os.path.join(data_dir, f'data/motion_map_iou/{uuid}.jpg')\n",
    "    # print(\"path: \", path)\n",
    "    img = cv2.imread(path)\n",
    "    w, h, c = img.shape\n",
    "    line_motion_heatmap = np.zeros([w, h, 3], np.uint8)\n",
    "    d = 100\n",
    "    points = [(int(box[0] + box[2]/2), int(box[1] + box[3]/2)) for box in boxes_list]\n",
    "    for id, boxes in enumerate(points):\n",
    "        if id != 0:\n",
    "            point1 = points[id-1]\n",
    "            point2 = points[id]\n",
    "            cv2.line(line_motion_heatmap, point1, point2, [0,255,255], 10)\n",
    "    return line_motion_heatmap\n",
    "\n",
    "for uuid in tracks_train:\n",
    "    # print(\"uuid: \", uuid)\n",
    "    boxes_list = tracks_train[uuid][\"boxes\"]\n",
    "    nl = tracks_train[uuid][\"nl\"][0]\n",
    "    motion = get_motion(nl)\n",
    "    text = \"straight\"\n",
    "    if motion is not None:\n",
    "        if \"left\" in motion:\n",
    "            text = \"left\"\n",
    "        elif \"right\" in motion:\n",
    "            text = \"right\"\n",
    "    line_motion_heatmap = get_motion_line(\"../data/AIC23_Track2_NL_Retrieval/data\", uuid, boxes_list)\n",
    "    cv2.putText(line_motion_heatmap, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imwrite(os.path.join(save_heatmap_dir, f'{uuid}.jpg'), line_motion_heatmap)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract points list each track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2155 2155\n",
      "184 184\n"
     ]
    }
   ],
   "source": [
    "points_list = []\n",
    "uuids = []\n",
    "for uuid in tracks_train:\n",
    "    uuids.append(uuid)\n",
    "    boxes_list = tracks_train[uuid][\"boxes\"]\n",
    "    points = []\n",
    "    for box in boxes_list:\n",
    "        x, y = int(box[0] + box[2]/2), int(box[1] + box[3]/2)\n",
    "        points.append(x)\n",
    "        points.append(y)\n",
    "    str_points = \",\".join([str(x) for x in points])\n",
    "    points_list.append(str_points)\n",
    "print(len(uuids), len(points_list))\n",
    "df = pd.DataFrame()\n",
    "df[\"uuids\"] = uuids\n",
    "df[\"points_list\"] = points_list\n",
    "df.to_csv(\"../data/AIC23_Track2_NL_Retrieval/data/train-tracks.csv\",index=False)\n",
    "\n",
    "\n",
    "points_list = []\n",
    "uuids = []\n",
    "for uuid in tracks_test:\n",
    "    uuids.append(uuid)\n",
    "    boxes_list = tracks_test[uuid][\"boxes\"]\n",
    "    points = []\n",
    "    for box in boxes_list:\n",
    "        x, y = int(box[0] + box[2]/2), int(box[1] + box[3]/2)\n",
    "        points.append(x)\n",
    "        points.append(y)\n",
    "    str_points = \",\".join([str(x) for x in points])\n",
    "    points_list.append(str_points)\n",
    "print(len(uuids), len(points_list))\n",
    "df = pd.DataFrame()\n",
    "df[\"uuids\"] = uuids\n",
    "df[\"points_list\"] = points_list\n",
    "df.to_csv(\"../data/AIC23_Track2_NL_Retrieval/data/test-tracks.csv\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get average lenght points list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuids</th>\n",
       "      <th>points_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b06c903c-a25d-45fe-b0d5-294f72e34023</td>\n",
       "      <td>675,744,667,772,661,800,657,819,654,861,647,88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3a02a86d-154b-4ee2-bd5e-a0811113a9d8</td>\n",
       "      <td>1493,439,1433,440,1372,442,1300,445,1287,446,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eb184f7c-35c7-4f3e-af52-1db57fb087d4</td>\n",
       "      <td>1815,476,1792,470,1756,458,1748,452,1716,445,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abd32535-8acb-49c5-8da4-9e904d263d8c</td>\n",
       "      <td>498,482,491,492,484,503,470,517,460,525,448,54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3819f85b-103a-4f0b-b0f1-49e6b2fedb68</td>\n",
       "      <td>1667,382,1594,383,1519,383,1447,382,1434,383,1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  uuids  \\\n",
       "0  b06c903c-a25d-45fe-b0d5-294f72e34023   \n",
       "1  3a02a86d-154b-4ee2-bd5e-a0811113a9d8   \n",
       "2  eb184f7c-35c7-4f3e-af52-1db57fb087d4   \n",
       "3  abd32535-8acb-49c5-8da4-9e904d263d8c   \n",
       "4  3819f85b-103a-4f0b-b0f1-49e6b2fedb68   \n",
       "\n",
       "                                         points_list  \n",
       "0  675,744,667,772,661,800,657,819,654,861,647,88...  \n",
       "1  1493,439,1433,440,1372,442,1300,445,1287,446,1...  \n",
       "2  1815,476,1792,470,1756,458,1748,452,1716,445,1...  \n",
       "3  498,482,491,492,484,503,470,517,460,525,448,54...  \n",
       "4  1667,382,1594,383,1519,383,1447,382,1434,383,1...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/AIC23_Track2_NL_Retrieval/data/train-tracks.csv\")\n",
    "points_list = []\n",
    "for line in df['points_list']:\n",
    "    points = line.split(',')\n",
    "    points_list.append(points)\n",
    "# average length of points\n",
    "length = 0\n",
    "for points in points_list:\n",
    "    length += len(points)\n",
    "print(length/len(points_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2155\n",
      "['675', '744', '667', '772', '661', '800', '657', '819', '654', '861', '647', '883', '639', '916']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171.8784222737819\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
